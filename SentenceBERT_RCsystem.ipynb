{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aapv9GIwsiqh",
        "outputId": "f3473ff1-ba72-41e3-8f2b-a68ecd783a47"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install transformers"
      ],
      "metadata": {
        "id": "vl28U0pCskQu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "7FGby7fVlo0H"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JAkSwp3jsrWG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_score(a, b):\n",
        "    if len(a.shape) == 1: a = a.unsqueeze(0)\n",
        "    if len(b.shape) == 1: b = b.unsqueeze(0)\n",
        "\n",
        "    a_norm = a / a.norm(dim=1)[:, None]\n",
        "    b_norm = b / b.norm(dim=1)[:, None]\n",
        "    return torch.mm(a_norm, b_norm.transpose(0, 1)) * 100"
      ],
      "metadata": {
        "id": "b0JaA4TNsuKX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModel.from_pretrained('BM-K/KoSimCSE-bert-multitask')  \n",
        "tokenizer = AutoTokenizer.from_pretrained('BM-K/KoSimCSE-bert-multitask')  "
      ],
      "metadata": {
        "id": "0_IXWPMpsw_3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('./Books.csv', encoding = 'utf-8')"
      ],
      "metadata": {
        "id": "2IJfKaHzvoKd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('./Self_Improvement.csv', encoding = 'utf-8')"
      ],
      "metadata": {
        "id": "CaNbb3D4jCYC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overview = test['overview'][0] #책소개를 넣어주세요."
      ],
      "metadata": {
        "id": "NojNE1q5fbJd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(overview, top = 10) :\n",
        "    \n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    tmp_score = []\n",
        "\n",
        "    for i in range(len(data)) :\n",
        "        if i % 100 == 0 :\n",
        "            print(i,'/', len(data))\n",
        "        tmp_sentence = [overview, data['overview'][i]]\n",
        "        inputs = tokenizer(tmp_sentence, padding = True, truncation = True, return_tensors = 'pt').to(device)\n",
        "        embeddings, _ = model(**inputs, return_dict = False)\n",
        "        score = get_score(embeddings[0][0], embeddings[1][0])[0][0].item()\n",
        "        tmp_score.append(score)\n",
        "\n",
        "    score = sorted(tmp_score, reverse = True)\n",
        "    score = [(data['title'][i], score) for i, score in enumerate(score[0:top])]\n",
        "\n",
        "    return score"
      ],
      "metadata": {
        "id": "P3yst5JReXre"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend(overview)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdhTo28Zileh",
        "outputId": "4bdf6b4b-defe-4575-e725-aa2eb849413f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 / 4176\n",
            "100 / 4176\n",
            "200 / 4176\n",
            "300 / 4176\n",
            "400 / 4176\n",
            "500 / 4176\n",
            "600 / 4176\n",
            "700 / 4176\n",
            "800 / 4176\n",
            "900 / 4176\n",
            "1000 / 4176\n",
            "1100 / 4176\n",
            "1200 / 4176\n",
            "1300 / 4176\n",
            "1400 / 4176\n",
            "1500 / 4176\n",
            "1600 / 4176\n",
            "1700 / 4176\n",
            "1800 / 4176\n",
            "1900 / 4176\n",
            "2000 / 4176\n",
            "2100 / 4176\n",
            "2200 / 4176\n",
            "2300 / 4176\n",
            "2400 / 4176\n",
            "2500 / 4176\n",
            "2600 / 4176\n",
            "2700 / 4176\n",
            "2800 / 4176\n",
            "2900 / 4176\n",
            "3000 / 4176\n",
            "3100 / 4176\n",
            "3200 / 4176\n",
            "3300 / 4176\n",
            "3400 / 4176\n",
            "3500 / 4176\n",
            "3600 / 4176\n",
            "3700 / 4176\n",
            "3800 / 4176\n",
            "3900 / 4176\n",
            "4000 / 4176\n",
            "4100 / 4176\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('내가 틀릴 수도 있습니다 - 숲속의 현자가 전하는 마지막 인생 수업', 78.64453125),\n",
              " ('마흔에 읽는 니체 - 지금 이 순간을 살기 위한 철학 수업', 75.15026092529297),\n",
              " ('당신도 느리게 나이 들 수 있습니다 - 나이가 들어도 몸의 시간은 젊게', 75.15026092529297),\n",
              " ('이어령의 마지막 수업', 74.11676788330078),\n",
              " ('지적 대화를 위한 넓고 얕은 지식 1 - 한 권으로 현실 세계를 통달하는 지식 여행서', 73.75979614257812),\n",
              " ('하루 한 장 고전 수업 - 365일 인생의 내공을 기르는', 73.60955810546875),\n",
              " ('오십에 읽는 논어 - 굽이치는 인생을 다잡아 주는 공자의 말', 73.60955810546875),\n",
              " ('최재천의 공부 - 어떻게 배우며 살 것인가', 73.40428924560547),\n",
              " ('사피엔스 - 유인원에서 사이보그까지, 인간 역사의 대담하고 위대한 질문', 73.20674133300781),\n",
              " ('빅 히스토리 - 우주와 지구, 인간을 하나로 잇는 새로운 역사', 72.91230010986328)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}