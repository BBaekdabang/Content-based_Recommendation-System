{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aapv9GIwsiqh",
        "outputId": "ee4638a9-c372-4296-a6ce-2f2366fdcd27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install transformers"
      ],
      "metadata": {
        "id": "vl28U0pCskQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JAkSwp3jsrWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_score(a, b):\n",
        "    if len(a.shape) == 1: a = a.unsqueeze(0)\n",
        "    if len(b.shape) == 1: b = b.unsqueeze(0)\n",
        "\n",
        "    a_norm = a / a.norm(dim=1)[:, None]\n",
        "    b_norm = b / b.norm(dim=1)[:, None]\n",
        "    return torch.mm(a_norm, b_norm.transpose(0, 1)) * 100"
      ],
      "metadata": {
        "id": "b0JaA4TNsuKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModel.from_pretrained('BM-K/KoSimCSE-bert-multitask')  \n",
        "tokenizer = AutoTokenizer.from_pretrained('BM-K/KoSimCSE-bert-multitask')  "
      ],
      "metadata": {
        "id": "0_IXWPMpsw_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('./Books.csv', encoding = 'utf-8')"
      ],
      "metadata": {
        "id": "2IJfKaHzvoKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overview = '' #책소개를 넣어주세요."
      ],
      "metadata": {
        "id": "NojNE1q5fbJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(overview, top = 10) :\n",
        "\n",
        "    score = []\n",
        "\n",
        "    for i in range(len(data)) :\n",
        "        tmp_sentence = [overview, data['overview'][i]]\n",
        "        inputs = tokenizer(tmp_sentence, padding = True, truncation = True, return_tensors = 'pt')\n",
        "        embeddings, _ = model(**inputs, return_dict = False)\n",
        "        score = get_score(embeddings[0][0], embeddings[1][0])[0][0].item()\n",
        "        score.append(score)\n",
        "\n",
        "    score = sorted(score, reverse = True)\n",
        "    score = [(data['title'][i], score) for i, score in enumerate(score[0:top])]\n",
        "\n",
        "    return score"
      ],
      "metadata": {
        "id": "P3yst5JReXre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8z4vK5-Nfv26"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}